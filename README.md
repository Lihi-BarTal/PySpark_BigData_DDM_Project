# ðŸ“Š Distributed Information Management & Big Data Analysis

**Python Project Portfolio using PySpark in a Distributed Environment**

---

## ðŸ’¡ Overview
This repository showcases solutions for complex Big Data challenges, focusing on distributed data management, optimization, and advanced analytics using the **Apache Spark** framework (implemented in PySpark/Databricks Notebooks).

## ðŸŽ¯ Core Technical Areas

The portfolio demonstrates expertise in three key phases of large-scale data processing:

1.  **Data Preparation & Feature Engineering:** Implementing complex data cleaning and transformation pipelines using PySpark DataFrames and Spark SQL.
2.  **Strategic Optimization:** Utilizing Spark for strategic analysis and **Influence Maximization** queries to optimize broadcasting decisions.
3.  **Advanced Analytics:** Implementing **Clustering Algorithms** (e.g., for viewing habits) and performing **Real-Time Streaming Analysis** on evolving data.

## ðŸ“„ Full Methodology Reports (DRY Files)

**All detailed technical analysis, methodology, and results are fully documented within the provided PDF reports.**

| Report File | Focus Area | Code File |
| :--- | :--- | :--- |
| **`project1_part1_dry.pdf`** | Data Cleaning and Complex Filtering. | `project1_part1.ipynb` |
| **`project1_part2_dry.pdf`** | Strategic Optimization and Audience Influence Maximization. | `project1_part2.ipynb` |
| **`PROJECT2_DRY.pdf`** | Clustering, Feature Extraction, and Real-Time Streaming Analysis. | `PROJECT2_WET.ipynb` |
